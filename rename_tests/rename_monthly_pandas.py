
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import pandas as pd
from datetime import datetime

FOLDER = "alertes_a_renommer/"
OUTPUT_FOLDER = "alertes_renommees_accent/"
DATE_MAX = datetime(2025, 11, 16, 23, 59, 59)
OUTPUT_INVALID = "lignes_invalides.csv"
OUTPUT_FILTERED = "lignes_filtrees.csv"

os.makedirs(OUTPUT_FOLDER, exist_ok=True)

invalid_rows = []
filtered_rows = []
total_initial = 0
total_final = 0
all_data = []

def fix_column_encoding(columns):
    """Corrige les colonnes mal encod√©es (ex: R√É¬©f√É¬©rence ‚Üí R√©f√©rence)."""
    fixed = []
    for col in columns:
        try:
            # R√©interpr√®te comme Latin-1 puis re-d√©code en UTF-8
            col_fixed = col.encode('latin1').decode('utf-8')
        except UnicodeEncodeError:
            col_fixed = col  # Si pas besoin de correction
        fixed.append(col_fixed)
    return fixed

if not os.path.exists(FOLDER):
    print(f"‚ùå Le dossier '{FOLDER}' n'existe pas.")
    exit(1)

for filename in os.listdir(FOLDER):
    if filename.lower().endswith(".csv"):
        file_path = os.path.join(FOLDER, filename)
        try:
            # df = pd.read_csv(file_path, sep=';', encoding='utf-8')
            df = pd.read_csv(file_path, sep=';', encoding='latin1', dtype=str)
            initial_count = len(df)
            total_initial += initial_count
            print(f"üìÇ Lecture : {filename} ({initial_count} lignes)")

            # Corrige les noms de colonnes
            df.columns = fix_column_encoding(df.columns)

            # Conversion Date avec format fran√ßais forc√©
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y %H:%M:%S', errors='coerce')
            else:
                df['Date'] = pd.NaT

            # Fallback sur Timestamp si Date invalide
            if 'Timestamp' in df.columns:
                mask_invalid = df['Date'].isna()
                if mask_invalid.any():
                    ts_sample = df.loc[mask_invalid, 'Timestamp'].dropna().astype(str).iloc[0]
                    if len(ts_sample) > 10:  # millisecondes
                        df.loc[mask_invalid, 'Date'] = pd.to_datetime(df.loc[mask_invalid, 'Timestamp'], unit='ms')
                    else:
                        df.loc[mask_invalid, 'Date'] = pd.to_datetime(df.loc[mask_invalid, 'Timestamp'], unit='s')

            # Afficher min/max avant filtrage
            if not df['Date'].dropna().empty:
                print(f"   ‚û°Ô∏è Dates min: {df['Date'].min()}, max: {df['Date'].max()}")

            # Lignes invalides
            invalid = df[df['Date'].isna()]
            if not invalid.empty:
                cols_to_keep = [c for c in ['R√©f√©rence', 'Date'] if c in invalid.columns]
                invalid = invalid[cols_to_keep]
                invalid['Source'] = filename
                invalid_rows.append(invalid)

            # Lignes filtr√©es (Date > DATE_MAX)
            filtered = df[df['Date'] > DATE_MAX]
            if not filtered.empty:
                cols_to_keep = [c for c in ['R√©f√©rence', 'Date'] if c in filtered.columns]
                filtered = filtered[cols_to_keep]
                filtered['Source'] = filename
                filtered_rows.append(filtered)

            # Supprimer invalides et filtr√©es
            df = df.dropna(subset=['Date'])
            df = df[df['Date'] <= DATE_MAX]

            final_count = len(df)
            total_final += final_count
            print(f"   ‚û°Ô∏è Conserv√©es : {final_count}, Perdues : {initial_count - final_count}")

            if final_count > 0:
                all_data.append(df)

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lecture {filename} : {e}")

# Sauvegarde des lignes invalides
if invalid_rows:
    invalid_df = pd.concat(invalid_rows, ignore_index=True)
    invalid_df.to_csv(OUTPUT_INVALID, sep=';', index=False, encoding='utf-8')
    print(f"‚úÖ Fichier g√©n√©r√© : {OUTPUT_INVALID} ({len(invalid_df)} lignes invalides)")
else:
    print("‚úÖ Aucune ligne invalide trouv√©e.")

# Sauvegarde des lignes filtr√©es
if filtered_rows:
    filtered_df = pd.concat(filtered_rows, ignore_index=True)
    filtered_df.to_csv(OUTPUT_FILTERED, sep=';', index=False, encoding='utf-8')
    print(f"‚úÖ Fichier g√©n√©r√© : {OUTPUT_FILTERED} ({len(filtered_df)} lignes filtr√©es)")
else:
    print("‚úÖ Aucune ligne filtr√©e trouv√©e.")

print(f"\nüìä Total initial : {total_initial}, Total final : {total_final}, Diff√©rence : {total_initial - total_final}")

if not all_data:
    print("‚ùå Aucun fichier valide trouv√©.")
    exit(1)

# Regroupement par mois
combined_df = pd.concat(all_data, ignore_index=True)
combined_df['Ann√©e'] = combined_df['Date'].dt.year
combined_df['Mois'] = combined_df['Date'].dt.month

file_count = 0
for (year, month), group in combined_df.groupby(['Ann√©e', 'Mois']):
    group = group.sort_values(by='Date')
    month_str = str(month).zfill(2)
    output_filename = f"alertes_{year}_{month_str}.csv"
    output_path = os.path.join(OUTPUT_FOLDER, output_filename)
    group.drop(columns=['Ann√©e', 'Mois']).to_csv(output_path, sep=';', index=False, encoding='utf-8')
    print(f"‚úÖ Fichier cr√©√© : {output_filename} ({len(group)} lignes)")
    file_count += 1

print(f"\nüéâ Op√©ration termin√©e : {file_count} fichiers g√©n√©r√©s dans '{OUTPUT_FOLDER}'")